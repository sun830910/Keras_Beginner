{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数式API简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用函数式API实现双输入问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 16)           3136        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_vocab_size = 10000\n",
    "ques_vocab_size = 10000\n",
    "ans_vocab_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedding_text = layers.Embedding(text_vocab_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedding_text)\n",
    "\n",
    "ques_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_ques = layers.Embedding(ques_vocab_size, 32)(ques_input)\n",
    "encoded_ques = layers.LSTM(16)(embedded_ques)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_ques], axis=-1)\n",
    "answer = layers.Dense(ans_vocab_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, ques_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据输入到多输入模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 17s 171ms/step - loss: 6.2148 - acc: 0.0032\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 14s 182ms/step - loss: 6.2005 - acc: 0.0055\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 6.1258 - acc: 0.0067\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 13s 166ms/step - loss: 5.9804 - acc: 0.0115\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 5.8150 - acc: 0.0222\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 5.6477 - acc: 0.0299\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 13s 160ms/step - loss: 5.4936 - acc: 0.0441\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 13s 171ms/step - loss: 5.3340 - acc: 0.0530\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 14s 175ms/step - loss: 5.1634 - acc: 0.0724\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 13s 160ms/step - loss: 4.9999 - acc: 0.0867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa36aae1750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "num_samples = 10000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocab_size, size=(num_samples, max_length))  # 生成虚构的Numpy数据\n",
    "ques = np.random.randint(1, ques_vocab_size, size=(num_samples, max_length))\n",
    "\n",
    "ans = np.random.randint(ans_vocab_size, size=(num_samples))\n",
    "ans = keras.utils.to_categorical(ans, ans_vocab_size)\n",
    "\n",
    "model.fit([text, ques], ans, epochs=10, batch_size=128)\n",
    "# model.fit({'text':text, 'question':ques}, ans, epochs=10, batch_size=128)  # 对输入有命名时可以这样用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多输出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocab_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedding_posts = layers.Embedding(vocab_size, 256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedding_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)  # 注意，输出层都具有名字\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 128)    163968      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 128)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    164096      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 256)    327936      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 256)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 256)    327936      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 256)    327936      conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输出模型的多重损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss={'age':'mse', 'income':'categorical_crossentropy', 'gender':'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], loss_weights=[0.25, 1., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss={'age':'mse', 'income':'categorical_crossentropy', 'gender':'binary_crossentropy'}, loss_weights={'age':0.25, 'income':1., 'gender':10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据输入到多输出模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-279e46f00c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mage_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'posts' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Keras回调函数和TensorBoard来检查并监控深度学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(  # 如果不再改善就中断训练\n",
    "        monitor='acc',  #监控模型的验证精度\n",
    "        patience=1,  # 如果精度在多于一轮的时间（即2轮）内不再改善就中断训练\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5',  # 在每轮过后保存当前权重\n",
    "        monitor='val_loss',  # 若val_loss没有改善，那么不需要覆盖模型文件，始终保存在训练过程中见到的最佳模型\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau：若验证损失不再改善，可以使用这个回调函数来降低学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',  # 监控模型的验证损失\n",
    "        factor=0.1,  # 触发时，将学习率*0.1\n",
    "        patience=10,  # 若验证损失在10轮内都没有改善，那么就触发这个回调函数\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写自己的回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    def set_model(self, model):\n",
    "        self.model = model  # 训练之前由父模型调用，告诉回调函数是哪个模型在调用它\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs)  # 模型实例，返回每层的激活\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "        validation_sample = self.validation_data[0][0:1]  # 获取验证数据的第一个输入样本\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')  # 将数据保存到硬盘\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard介绍\n",
    "Tensorflow的可视化框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = imdb.load_data(num_words=max_features)\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=max_len)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "                          input_length=max_len,\n",
    "                          name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir my_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_神经网络与数学基础.ipynb\r\n",
      "L3_神经网络入门.ipynb\r\n",
      "L6_深度学习用于文本和序列.ipynb\r\n",
      "L7_高级的深度学习最佳实践.ipynb\r\n",
      "\u001b[34mmy_log_dir\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用一个TensorBoard回调函数来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = 'my_log_dir',  # 日志文件将被写入这个位置\n",
    "        histogram_freq=1,  # 每一轮之后记录激活直方图\n",
    "        embeddings_freq=1  # 每一轮之后记录嵌入数据\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 47s 294ms/step - loss: 4.4006 - acc: 0.5357 - val_loss: 0.4293 - val_acc: 0.8306\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 42s 268ms/step - loss: 0.4653 - acc: 0.8415 - val_loss: 0.4258 - val_acc: 0.8610\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 53s 339ms/step - loss: 0.3847 - acc: 0.8819 - val_loss: 0.4252 - val_acc: 0.8674\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 45s 287ms/step - loss: 0.3141 - acc: 0.9024 - val_loss: 0.7697 - val_acc: 0.8180\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 0.3068 - acc: 0.9208 - val_loss: 0.7329 - val_acc: 0.8472\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 57s 361ms/step - loss: 0.2350 - acc: 0.9473 - val_loss: 0.5750 - val_acc: 0.8722\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 46s 293ms/step - loss: 0.1954 - acc: 0.9610 - val_loss: 0.8596 - val_acc: 0.8498\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 51s 322ms/step - loss: 0.1829 - acc: 0.9704 - val_loss: 0.7237 - val_acc: 0.8696\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.1448 - acc: 0.9822 - val_loss: 0.8547 - val_acc: 0.8644\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 60s 381ms/step - loss: 0.1377 - acc: 0.9859 - val_loss: 1.0115 - val_acc: 0.8636\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 46s 291ms/step - loss: 0.1118 - acc: 0.9898 - val_loss: 1.7160 - val_acc: 0.7998\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 39s 250ms/step - loss: 0.1198 - acc: 0.9880 - val_loss: 1.0018 - val_acc: 0.8660\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 40s 255ms/step - loss: 0.1252 - acc: 0.9896 - val_loss: 1.2797 - val_acc: 0.8564\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 45s 284ms/step - loss: 0.1022 - acc: 0.9909 - val_loss: 1.1691 - val_acc: 0.8586\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 43s 273ms/step - loss: 0.1023 - acc: 0.9890 - val_loss: 1.1557 - val_acc: 0.8674\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 41s 262ms/step - loss: 0.0998 - acc: 0.9923 - val_loss: 1.3021 - val_acc: 0.8558\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 44s 277ms/step - loss: 0.0931 - acc: 0.9920 - val_loss: 1.1789 - val_acc: 0.8696\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 50s 320ms/step - loss: 0.0844 - acc: 0.9932 - val_loss: 1.1715 - val_acc: 0.8678\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 45s 284ms/step - loss: 0.0900 - acc: 0.9928 - val_loss: 1.1498 - val_acc: 0.8716\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 39s 246ms/step - loss: 0.0972 - acc: 0.9926 - val_loss: 1.2443 - val_acc: 0.8666\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                   epochs=20,\n",
    "                   batch_size=128,\n",
    "                   validation_split=0.2,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过命令行启动TensorBoard服务器\n",
    "$ tensorboard --logfir=my_log_dir  \n",
    "然后可以用浏览器打开 http://localhost:6006 查看模型的训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示模型结构\n",
    "可以使用keras.utils.plot_model函数绘制由层组成的图，使用这个函数需要安装Python的pydot库和pydot-ng库还需要安装graphviz库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 让模型性能发挥到极致\n",
    "1. 在网络每一次变换之后都应该考虑数据标准化，即使输入层中的数据均值为0、方差为1，也没有理由假定网络输出的数据也是这样。可以使用批标准化（batch normalization），即使在训练过程中均值和方差随时间发生变化，也可以适应性的将数据标准化。 标准化的工作原理是，训练过程中在内部保存已读取每批数据均值和方差的指数移动平均值。标准化的主要效果是有助于梯度传播，因此运训更深的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())  # 在卷积层之后使用\n",
    "\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())  # 在Dense层后使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
